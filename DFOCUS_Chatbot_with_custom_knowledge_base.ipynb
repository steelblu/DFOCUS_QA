{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwaLK4kD1Uar"
      },
      "source": [
        "#Introduction\n",
        "\n",
        "This notebook has all the code you need to create your own chatbot with custom knowledge base using GPT-3. \n",
        "\n",
        "Follow the instructions for each steps and then run the code sample. In order to run the code, you need to press \"play\" button near each code sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0U7D-ChF-Jx"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD4Qzglp3J-h"
      },
      "source": [
        "#Download the data for your custom knowledge base\n",
        "For the demonstration purposes we are going to use ----- as our knowledge base. You can download them to your local folder from the github repository by running the code below.\n",
        "Alternatively, you can put your own custom data into the local folder. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cCyU-vV5Yb0",
        "outputId": "a8bdd29a-c865-4955-916f-9c37955e51eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'DFOCUS_QA'...\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/steelblu/DFOCUS_QA.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiUyHP4T2g5F"
      },
      "source": [
        "# Install the dependicies\n",
        "Run the code below to install the depencies we need for our functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6LL4rxT6_W7h"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gpt-index\n",
            "  Using cached gpt_index-0.4.23-py3-none-any.whl (231 kB)\n",
            "Requirement already satisfied: dataclasses-json in c:\\python311\\lib\\site-packages (from gpt-index) (0.5.7)\n",
            "Requirement already satisfied: langchain in c:\\python311\\lib\\site-packages (from gpt-index) (0.0.105)\n",
            "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (from gpt-index) (1.24.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\python311\\lib\\site-packages (from gpt-index) (8.2.2)\n",
            "Requirement already satisfied: openai>=0.26.4 in c:\\python311\\lib\\site-packages (from gpt-index) (0.27.1)\n",
            "Requirement already satisfied: pandas in c:\\python311\\lib\\site-packages (from gpt-index) (1.5.3)\n",
            "Requirement already satisfied: tiktoken in c:\\python311\\lib\\site-packages (from gpt-index) (0.3.0)\n",
            "Requirement already satisfied: requests>=2.20 in c:\\python311\\lib\\site-packages (from openai>=0.26.4->gpt-index) (2.28.2)\n",
            "Requirement already satisfied: tqdm in c:\\python311\\lib\\site-packages (from openai>=0.26.4->gpt-index) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in c:\\python311\\lib\\site-packages (from openai>=0.26.4->gpt-index) (3.8.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\python311\\lib\\site-packages (from dataclasses-json->gpt-index) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\python311\\lib\\site-packages (from dataclasses-json->gpt-index) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\python311\\lib\\site-packages (from dataclasses-json->gpt-index) (0.8.0)\n",
            "Requirement already satisfied: PyYAML<7,>=6 in c:\\python311\\lib\\site-packages (from langchain->gpt-index) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in c:\\python311\\lib\\site-packages (from langchain->gpt-index) (1.4.46)\n",
            "Requirement already satisfied: pydantic<2,>=1 in c:\\python311\\lib\\site-packages (from langchain->gpt-index) (1.10.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\jhlee\\appdata\\roaming\\python\\python311\\site-packages (from pandas->gpt-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas->gpt-index) (2022.7.1)\n",
            "Requirement already satisfied: blobfile>=2 in c:\\python311\\lib\\site-packages (from tiktoken->gpt-index) (2.0.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\python311\\lib\\site-packages (from tiktoken->gpt-index) (2022.10.31)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\python311\\lib\\site-packages (from aiohttp->openai>=0.26.4->gpt-index) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\python311\\lib\\site-packages (from aiohttp->openai>=0.26.4->gpt-index) (3.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python311\\lib\\site-packages (from aiohttp->openai>=0.26.4->gpt-index) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\python311\\lib\\site-packages (from aiohttp->openai>=0.26.4->gpt-index) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python311\\lib\\site-packages (from aiohttp->openai>=0.26.4->gpt-index) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python311\\lib\\site-packages (from aiohttp->openai>=0.26.4->gpt-index) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python311\\lib\\site-packages (from aiohttp->openai>=0.26.4->gpt-index) (1.3.1)\n",
            "Requirement already satisfied: pycryptodomex~=3.8 in c:\\python311\\lib\\site-packages (from blobfile>=2->tiktoken->gpt-index) (3.17)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in c:\\python311\\lib\\site-packages (from blobfile>=2->tiktoken->gpt-index) (1.26.14)\n",
            "Requirement already satisfied: lxml~=4.9 in c:\\python311\\lib\\site-packages (from blobfile>=2->tiktoken->gpt-index) (4.9.2)\n",
            "Requirement already satisfied: filelock~=3.0 in c:\\python311\\lib\\site-packages (from blobfile>=2->tiktoken->gpt-index) (3.9.0)\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\users\\jhlee\\appdata\\roaming\\python\\python311\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->gpt-index) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\python311\\lib\\site-packages (from pydantic<2,>=1->langchain->gpt-index) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\jhlee\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.1->pandas->gpt-index) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests>=2.20->openai>=0.26.4->gpt-index) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests>=2.20->openai>=0.26.4->gpt-index) (2022.12.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\python311\\lib\\site-packages (from SQLAlchemy<2,>=1->langchain->gpt-index) (2.0.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\python311\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json->gpt-index) (1.0.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\jhlee\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->openai>=0.26.4->gpt-index) (0.4.6)\n",
            "Installing collected packages: gpt-index\n",
            "Successfully installed gpt-index-0.4.23\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 23.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in c:\\python311\\lib\\site-packages (0.0.105)\n",
            "Requirement already satisfied: PyYAML<7,>=6 in c:\\python311\\lib\\site-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in c:\\python311\\lib\\site-packages (from langchain) (1.4.46)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\python311\\lib\\site-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\python311\\lib\\site-packages (from langchain) (0.5.7)\n",
            "Requirement already satisfied: numpy<2,>=1 in c:\\python311\\lib\\site-packages (from langchain) (1.24.2)\n",
            "Requirement already satisfied: pydantic<2,>=1 in c:\\python311\\lib\\site-packages (from langchain) (1.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\python311\\lib\\site-packages (from langchain) (2.28.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\python311\\lib\\site-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\python311\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\python311\\lib\\site-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\users\\jhlee\\appdata\\roaming\\python\\python311\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\python311\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 23.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.Collecting transformers\n",
            "  Using cached transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\python311\\lib\\site-packages (from transformers) (0.13.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\python311\\lib\\site-packages (from transformers) (1.24.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\jhlee\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\python311\\lib\\site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\python311\\lib\\site-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in c:\\python311\\lib\\site-packages (from transformers) (2.28.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\python311\\lib\\site-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\python311\\lib\\site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\jhlee\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: transformers\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
            "ERROR: Could not install packages due to an OSError: [WinError 2] 지정된 파일을 찾을 수 없습니다: 'c:\\\\Python311\\\\Scripts\\\\transformers-cli.exe' -> 'c:\\\\Python311\\\\Scripts\\\\transformers-cli.exe.deleteme'\n",
            "\n",
            "\n",
            "[notice] A new release of pip available: 22.3 -> 23.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install gpt-index\n",
        "%pip install langchain\n",
        "%pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbuYetOy25eM"
      },
      "source": [
        "# Define the functions\n",
        "The following code defines the functions we need to construct the index and query it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UelAqQgk_yIt"
      },
      "outputs": [],
      "source": [
        "from gpt_index import SimpleDirectoryReader, GPTListIndex, readers, GPTSimpleVectorIndex, LLMPredictor, PromptHelper\n",
        "from langchain import OpenAI\n",
        "import sys\n",
        "import os\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "def construct_index(directory_path):\n",
        "    # set maximum input size\n",
        "    max_input_size = 4096\n",
        "    # set number of output tokens\n",
        "    num_outputs = 300\n",
        "    # set maximum chunk overlap\n",
        "    max_chunk_overlap = 20\n",
        "    # set chunk size limit\n",
        "    chunk_size_limit = 600 \n",
        "\n",
        "    # define LLM\n",
        "    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0.5, model_name=\"text-davinci-003\", max_tokens=num_outputs))\n",
        "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
        " \n",
        "    documents = SimpleDirectoryReader(directory_path).load_data()\n",
        "    \n",
        "    index = GPTSimpleVectorIndex(\n",
        "        documents, llm_predictor=llm_predictor, prompt_helper=prompt_helper\n",
        "    )\n",
        "\n",
        "    index.save_to_disk('index.json')\n",
        "\n",
        "    return index\n",
        "\n",
        "def ask_ai():\n",
        "    index = GPTSimpleVectorIndex.load_from_disk('index.json')\n",
        "    while True: \n",
        "        query = input(\"What do you want to ask? \")\n",
        "        response = index.query(query, response_mode=\"compact\")\n",
        "        display(Markdown(f\"Response: <b>{response.response}</b>\"))\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz1jp33jGumu"
      },
      "source": [
        "# Set OpenAI API Key\n",
        "You need an OPENAI API key to be able to run this code.\n",
        "\n",
        "If you don't have one yet, get it by [signing up](https://platform.openai.com/overview). Then click your account icon on the top right of the screen and select \"View API Keys\". Create an API key.\n",
        "\n",
        "Then run the code below and paste your API key into the text input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoJHE4fsAT3w",
        "outputId": "547befb0-7182-4589-fa37-dc902f8f4edd"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = input(\"Paste your OpenAI key here and hit enter:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVrddlAL4I_v"
      },
      "source": [
        "#Construct an index\n",
        "Now we are ready to construct the index. This will take every file in the folder 'data', split it into chunks, and embed it with OpenAI's embeddings API.\n",
        "\n",
        "**Notice:** running this code will cost you credits on your OpenAPI account ($0.02 for every 1,000 tokens). If you've just set up your account, the free credits that you have should be more than enough for this experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCYTE2EqBB7O",
        "outputId": "d5d6828e-c9c7-4bad-d0fb-ec73e94cdd53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<gpt_index.indices.vector_store.vector_indices.GPTSimpleVectorIndex at 0x7f24cc841280>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "construct_index(\"DFOCUS_QA/data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipJ_gYxN5cWh"
      },
      "source": [
        "#Ask questions\n",
        "It's time to have fun and test our AI. Run the function that queries GPT and type your question into the input. \n",
        "\n",
        "If you've used the provided example data for your custom knowledge base, here are a few questions that you can ask:\n",
        "1. seedCloud는?\n",
        "2. 디포커스는?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "id": "s_uwsPGEIGsb",
        "outputId": "52c8d26a-d80c-4fa2-ee6d-86a145afa4fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What do you want to ask? seedCloud가 뭐야\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Response: <b>\n",
              "SeedCloud는 포털 솔루션으로, 다양한 오토스케일러 그룹을 관리하고 CPU, Memory 기반의 자원을 증가시켜주는 Scale-Up/Out 기능과 사용자 정의 기능, 커스텀 작업 처리 옵션 기능, IP Pool을 기반으로 한 자동화된 IP 충돌 방지 기능을 제공하는 플</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What do you want to ask? 대한민국 대통령은?\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Response: <b>\n",
              "문재인입니다.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What do you want to ask? 지금 몇년도야\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Response: <b>\n",
              "2023년</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What do you want to ask? 운영비용을 점감하기 위한 좋은 솔루션은?\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Response: <b>\n",
              "A good solution for reducing operational costs is to use a cloud management portal such as SEEDCLOUD. This portal can help integrate external hosting systems, streamline IT resources, and manage complex and varied requirements for large enterprises.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What do you want to ask? 전화번호\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Response: <b>\n",
              "010-7211-0616</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What do you want to ask? 전화\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Response: <b>문의는 어디로 하면 됩니까?\n",
              "\n",
              "전화 문의는 010-7211-0616로 하시면 됩니다.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-73fd53e5fb33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mask_ai\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-775ed1c88e3f>\u001b[0m in \u001b[0;36mask_ai\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPTSimpleVectorIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What do you want to ask? \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"compact\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Response: <b>{response.response}</b>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "ask_ai()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "XiUyHP4T2g5F"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
